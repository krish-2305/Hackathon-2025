{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2910,
     "status": "ok",
     "timestamp": 1755705769289,
     "user": {
      "displayName": "Krishnan R",
      "userId": "09129740586849182851"
     },
     "user_tz": -330
    },
    "id": "Llihfk7VFpVH",
    "outputId": "86d98cb4-92c7-4855-e73f-9d4f96decf9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbhDEIU2KSz2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1755704820424,
     "user": {
      "displayName": "Krishnan R",
      "userId": "09129740586849182851"
     },
     "user_tz": -330
    },
    "id": "AI1CUjdrGexh",
    "outputId": "62a9b279-5920-475f-8522-63d94f49a14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/Dataset.zip\n",
      "  inflating: /content/drive/MyDrive/Dataset/README.dataset.txt  \n",
      "  inflating: /content/drive/MyDrive/Dataset/README.roboflow.txt  \n",
      "   creating: /content/drive/MyDrive/Dataset/train/\n",
      "  inflating: /content/drive/MyDrive/Dataset/train/_annotations.coco.json  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_10_png.rf.e93923fab7a4d852bcc87747de90abe8.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_11_png.rf.2322955a1c5bf5b13f6306e454aea228.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_12_png.rf.9f915fdb7868a316601718ff0adff6a3.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_13_png.rf.971647d529006f7913ce77aced0c48e3.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_14_png.rf.cd7221022ed1be4b57e6279da896e9c4.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_16_png.rf.1dc07b6d124966ae7b70b364cde62b78.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_17_png.rf.0ef4a2daeedafd0dc114e15bce48d7f0.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_18_png.rf.53a106a58f70d35041e6653c43961e48.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_19_png.rf.07041658398e83421f3ccb0fe833e475.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_1_png.rf.d47d8ab064d23acefca75d4d9dfe299d.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_20_png.rf.0903867a5f5c2a9cd268668728141e40.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_22_png.rf.636475424fee38952acc456cc48bdfab.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_23_png.rf.e2c0f80b1f7c47264125e7893fff3e32.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_24_png.rf.7e8eaa93883c3bebf3e88addfeff77bd.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_2_png.rf.6a5120eaca65a37ac41d0a60f7b69276.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_3_png.rf.303085f18402fedbe55629905e37cdc4.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_4_png.rf.829f6016437b2fd9802e5ab5dbe5256b.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_5_png.rf.8b1a2c91a7b78e21a6e43108abbf2552.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_6_png.rf.6ffd8dd7bdc901e69026880b32ad1446.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_7_png.rf.7dc079bdd39a3af663e49b558fb70f9a.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_8_png.rf.3ed3a4b360dd82aec439e91e42540103.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut1_9_png.rf.039bb7d37dde209a6a1d8754b173cdea.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_10_png.rf.e6d13e961618ca6af725b4a58ee97a5c.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_11_png.rf.f43aac793924ca82a0c4b21b19e4e6e2.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_12_png.rf.02e143627310b545a5360bb84b3919ab.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_13_png.rf.f42995a226dd05307742f952d4547cbb.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_14_png.rf.cb439fff7d8f4f34980cda365628353b.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_15_png.rf.2781932ff9005dfaf103fc052497c9a9.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_16_png.rf.30b921636d391ac7d32e59f7fb71ef29.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_17_png.rf.720790331d251031967d58ced1e8448f.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_18_png.rf.4f4c9616b7f3451003f17cd3424d1261.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_19_png.rf.fe47d73447a05c59f7a15f7fca00e590.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_1_png.rf.1b093e06646c4a1d59bca23960a7fc50.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_20_png.rf.7e3c00a13c38896c3f66637bd4026de9.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_21_png.rf.53eb0c2c475ccff459d9046b952a8ae0.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_22_png.rf.44be8fb073f0da4dedab707bd49b9eb4.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_23_png.rf.9327b1106ac23e062d17d653e5e0d4ae.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_24_png.rf.3b4004ecc89ee465d635ef7aad4b3a24.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_25_png.rf.e145335261bf999ed3d1b94a971ce7fa.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_2_png.rf.2bfe4dfd167280147e360dcd0bb19756.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_3_png.rf.7c6db458a281d1b431edd0d6474eabb1.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_4_png.rf.9e26383137050f043d0bc196bbe1f851.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_5_png.rf.c69dbfb58022c62534ccce57c6f33e46.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_6_png.rf.5896523ff177d6ccdaecfc9c1f4d364f.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_7_png.rf.322f67667fa511d3829061cb23709f1c.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_8_png.rf.273e2a9173d70e49425feb50b6498783.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/cut2_9_png.rf.d5cc54cd57294623e0652d1584f52468.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_10_png.rf.9a29dae0d92e7f1290636aa36facd615.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_11_png.rf.dc5b26f964ae8cd1170b20d2b212cde5.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_12_png.rf.f246c0b0359c813676f0d85235c18807.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_13_png.rf.2f7a552688f79673b414634748a0bacc.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_14_png.rf.1329c2d6e6778e935affe5b9bb914aa4.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_15_png.rf.bdffe33e68f06d0ed27a4879d9aead34.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_16_png.rf.a0cd8c4c64408c6121684f9901c2c3ec.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_17_png.rf.18758d9777ca046e0fe2f6da4b07c491.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_18_png.rf.1f5ca9cb2984e5b7e672a21bb94dcef4.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_19_png.rf.046ecdcb2d3c7e9863d562d721cf54d3.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_1_png.rf.023a77ad22904bdb26d59a117891fe0a.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_20_png.rf.754974bdde1a423279b1b61aaeb8cb8d.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_21_png.rf.a1048c08b6bafa28df5f8c8b9d26c858.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_22_png.rf.1cff47a0ff7faeefe26abddcdb543053.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_23_png.rf.39f81dd64c82456e282e05f0612f0585.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_24_png.rf.4a9a238f28b8590ac9c5a25fb15517cb.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_25_png.rf.c967e2fdc140b5ad4f5be702e099d86d.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_2_png.rf.65fbd668c02abc1b17d0618ad9526e0e.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_3_png.rf.3e7632dfecf6572ee830a74cedafc235.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_4_png.rf.890ce96ebc2f4a74877f6735d321d74c.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_5_png.rf.bce2521d9d323773f497b29b62bfbdb2.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_6_png.rf.d501b582819e3f88f2e22c61aebd03c0.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_7_png.rf.913f0ee4ae99cfe44489d367f8ae8a93.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_8_png.rf.1492fa6599ce249487594a6b2e7207d1.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash1_9_png.rf.5c14e8128a62b761b8d3f85471e7c2c5.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_10_png.rf.fe0cf57c6cfecc6023a1ee4f46505303.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_11_png.rf.7c2a5f23237db59113bcf540aac6ba98.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_12_png.rf.97e1baf939d4093a28d7214f97291a87.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_13_png.rf.7cf07ce71367882f1dc6112886a4f975.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_14_png.rf.12d5b6c2b4b6dd4792671563888130db.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_15_png.rf.368d97d59ca4c95e92851f31e1c97e5a.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_17_png.rf.f3cfae705c11b43254f63cd790ccc553.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_18_png.rf.4a3b8afe0cb430dc3aa0de25aedca8e7.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_19_png.rf.0c1e6920b94e41614c315625f1825a45.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_1_png.rf.c51fd2461692dd52e6271e14d62793ec.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_20_png.rf.46c8224a86a2cfbf2899f9dc57c1894b.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_21_png.rf.4091e848031ffe08c1f5da0443051552.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_23_png.rf.58c8b0804ee431729a9442d6ac04c7f8.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_24_png.rf.065afcf13225c53f5437b634e357f92b.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_25_png.rf.f5bdc7979fba1b108ac7192011182acc.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_2_png.rf.c3f8abac60336caf9ff80702446f3a80.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_3_png.rf.156d6f617f8a940ad1e6d337d0ff413d.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_4_png.rf.cadf275487c85b3401d4c83ab14456bc.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_5_png.rf.710edfcdbdd2d6d6ea9bdc3cf3e05553.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_6_png.rf.6f4302eb93c6ae64bbcbb5dfec066582.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_7_png.rf.5ebb340f7d9b96fb1d224f54f7f87d69.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_8_png.rf.875e7fe7e083077417f9618c6a3401d8.jpg  \n",
      " extracting: /content/drive/MyDrive/Dataset/train/flash2_9_png.rf.3dc8afcc863631891fe54c63191a91ba.jpg  \n"
     ]
    }
   ],
   "source": [
    "!unzip /content/drive/MyDrive/Dataset.zip -d /content/drive/MyDrive/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 181749,
     "status": "ok",
     "timestamp": 1755705411302,
     "user": {
      "displayName": "Krishnan R",
      "userId": "09129740586849182851"
     },
     "user_tz": -330
    },
    "id": "5qF2YH6PJSGI",
    "outputId": "140170ca-37bc-44c7-ea1e-9fe34c38dfaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pycocotools) (2.0.2)\n",
      "Warning: Found 96 images, expected 95\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "All images found\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Debugging dataset:\n",
      "Sample 0: Target = [{'id': 0, 'image_id': 0, 'category_id': 1, 'bbox': [561, 267, 37, 54.5], 'area': 2016.5, 'segmentation': [], 'iscrowd': 0}]\n",
      "Sample 1: Target = [{'id': 1, 'image_id': 1, 'category_id': 1, 'bbox': [452, 187, 49, 48], 'area': 2352, 'segmentation': [], 'iscrowd': 0}]\n",
      "Sample 2: Target = [{'id': 2, 'image_id': 2, 'category_id': 1, 'bbox': [375, 363, 41, 59.5], 'area': 2439.5, 'segmentation': [], 'iscrowd': 0}]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Using device: cuda\n",
      "Epoch [1/10], Loss: 0.3661\n",
      "Epoch [2/10], Loss: 0.2647\n",
      "Epoch [3/10], Loss: 0.2648\n",
      "Epoch [4/10], Loss: 0.2622\n",
      "Epoch [5/10], Loss: 0.2561\n",
      "Epoch [6/10], Loss: 0.2461\n",
      "Epoch [7/10], Loss: 0.2404\n",
      "Epoch [8/10], Loss: 0.2361\n",
      "Epoch [9/10], Loss: 0.2359\n",
      "Epoch [10/10], Loss: 0.2362\n",
      "Model saved to 'defect_detection_model.pth'\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Test Image 1 (File: cut1_3_png.rf.303085f18402fedbe55629905e37cdc4.jpg):\n",
      "Ground Truth: Cut, Box: [tensor(10.), tensor(409.), tensor(45.5000), tensor(45.5000)]\n",
      "  - Predicted: Class: Cut, Score: 0.66, Box: [  4.871826 393.1344    58.28465  457.4046  ]\n",
      "  - Predicted: Class: Flash, Score: 0.53, Box: [ 12.28313  396.25815   51.104427 460.4632  ]\n",
      "Visualization saved to 'test_predictions/test_image_1_cut1_3_png.rf.303085f18402fedbe55629905e37cdc4.jpg'\n",
      "\n",
      "Test Image 2 (File: flash2_18_png.rf.4a3b8afe0cb430dc3aa0de25aedca8e7.jpg):\n",
      "Ground Truth: Flash, Box: [tensor(60.), tensor(482.), tensor(49.5000), tensor(53.)]\n",
      "  - Predicted: Class: Cut, Score: 0.59, Box: [ 55.447674 472.09518  109.02783  530.4097  ]\n",
      "Visualization saved to 'test_predictions/test_image_2_flash2_18_png.rf.4a3b8afe0cb430dc3aa0de25aedca8e7.jpg'\n",
      "\n",
      "Test Image 3 (File: flash2_11_png.rf.7c2a5f23237db59113bcf540aac6ba98.jpg):\n",
      "Ground Truth: Flash, Box: [tensor(599.), tensor(192.), tensor(38.), tensor(45.5000)]\n",
      "  - Predicted: Class: Flash, Score: 0.60, Box: [602.60596 190.83226 637.4541  238.51688]\n",
      "Visualization saved to 'test_predictions/test_image_3_flash2_11_png.rf.7c2a5f23237db59113bcf540aac6ba98.jpg'\n",
      "\n",
      "Test Image 4 (File: cut1_6_png.rf.6ffd8dd7bdc901e69026880b32ad1446.jpg):\n",
      "Ground Truth: Cut, Box: [tensor(128.), tensor(145.), tensor(48.), tensor(50.)]\n",
      "  - Predicted: Class: Cut, Score: 0.65, Box: [133.02824 142.99164 182.19742 189.37277]\n",
      "Visualization saved to 'test_predictions/test_image_4_cut1_6_png.rf.6ffd8dd7bdc901e69026880b32ad1446.jpg'\n",
      "\n",
      "Test Image 5 (File: flash1_8_png.rf.1492fa6599ce249487594a6b2e7207d1.jpg):\n",
      "Ground Truth: Flash, Box: [tensor(440.), tensor(243.), tensor(43.5000), tensor(46.5000)]\n",
      "  - Predicted: Class: Cut, Score: 0.59, Box: [448.93082 235.05696 492.29108 287.37234]\n",
      "Visualization saved to 'test_predictions/test_image_5_flash1_8_png.rf.1492fa6599ce249487594a6b2e7207d1.jpg'\n",
      "\n",
      "Test Image 6 (File: cut2_12_png.rf.02e143627310b545a5360bb84b3919ab.jpg):\n",
      "Ground Truth: Cut, Box: [tensor(385.), tensor(332.), tensor(58.5000), tensor(52.)]\n",
      "  - Predicted: Class: Cut, Score: 0.66, Box: [392.47827 328.97226 438.03317 389.41733]\n",
      "Visualization saved to 'test_predictions/test_image_6_cut2_12_png.rf.02e143627310b545a5360bb84b3919ab.jpg'\n",
      "\n",
      "Test Image 7 (File: cut2_13_png.rf.f42995a226dd05307742f952d4547cbb.jpg):\n",
      "Ground Truth: Cut, Box: [tensor(433.), tensor(229.), tensor(49.5000), tensor(58.)]\n",
      "  - Predicted: Class: Cut, Score: 0.69, Box: [441.15884 230.81555 492.04086 285.74734]\n",
      "Visualization saved to 'test_predictions/test_image_7_cut2_13_png.rf.f42995a226dd05307742f952d4547cbb.jpg'\n",
      "\n",
      "Test Image 8 (File: flash2_5_png.rf.710edfcdbdd2d6d6ea9bdc3cf3e05553.jpg):\n",
      "Ground Truth: Flash, Box: [tensor(94.), tensor(447.), tensor(54.5000), tensor(51.)]\n",
      "  - Predicted: Class: Cut, Score: 0.60, Box: [ 88.46037 442.60568 151.80435 491.37802]\n",
      "Visualization saved to 'test_predictions/test_image_8_flash2_5_png.rf.710edfcdbdd2d6d6ea9bdc3cf3e05553.jpg'\n",
      "\n",
      "Test Image 9 (File: flash1_1_png.rf.023a77ad22904bdb26d59a117891fe0a.jpg):\n",
      "Ground Truth: Flash, Box: [tensor(234.), tensor(371.), tensor(47.5000), tensor(51.)]\n",
      "  - Predicted: Class: Flash, Score: 0.66, Box: [228.15205 365.69797 279.9857  431.19003]\n",
      "  - Predicted: Class: Cut, Score: 0.51, Box: [224.22986 352.14944 291.37537 432.6594 ]\n",
      "Visualization saved to 'test_predictions/test_image_9_flash1_1_png.rf.023a77ad22904bdb26d59a117891fe0a.jpg'\n",
      "\n",
      "Test Image 10 (File: flash1_11_png.rf.dc5b26f964ae8cd1170b20d2b212cde5.jpg):\n",
      "Ground Truth: Flash, Box: [tensor(453.), tensor(229.), tensor(54.), tensor(54.5000)]\n",
      "  - Predicted: Class: Flash, Score: 0.58, Box: [458.10507 228.79626 508.0371  285.0176 ]\n",
      "  - Predicted: Class: Cut, Score: 0.54, Box: [447.84854 226.44046 509.0577  279.6247 ]\n",
      "Visualization saved to 'test_predictions/test_image_10_flash1_11_png.rf.dc5b26f964ae8cd1170b20d2b212cde5.jpg'\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.50 | area=   all | maxDets=100 ] = 0.752\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.50 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.50 | area=medium | maxDets=100 ] = 0.752\n",
      " Average Precision  (AP) @[ IoU=0.50:0.50 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area=   all | maxDets=  1 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area=   all | maxDets= 10 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area=   all | maxDets=100 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area=medium | maxDets=100 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area= large | maxDets=100 ] = -1.000\n",
      "Test mAP@0.5: 0.7525\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_65758da0-d526-4756-9c6c-bf09e2fc3f5d\", \"defect_detection_model.pth\", 165752788)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: test_predictions/ (stored 0%)\n",
      "  adding: test_predictions/test_image_8_flash2_5_png.rf.710edfcdbdd2d6d6ea9bdc3cf3e05553.jpg (deflated 40%)\n",
      "  adding: test_predictions/test_image_1_cut1_3_png.rf.303085f18402fedbe55629905e37cdc4.jpg (deflated 40%)\n",
      "  adding: test_predictions/test_image_5_flash1_8_png.rf.1492fa6599ce249487594a6b2e7207d1.jpg (deflated 39%)\n",
      "  adding: test_predictions/test_image_9_flash1_1_png.rf.023a77ad22904bdb26d59a117891fe0a.jpg (deflated 40%)\n",
      "  adding: test_predictions/test_image_4_cut1_6_png.rf.6ffd8dd7bdc901e69026880b32ad1446.jpg (deflated 42%)\n",
      "  adding: test_predictions/test_image_10_flash1_11_png.rf.dc5b26f964ae8cd1170b20d2b212cde5.jpg (deflated 37%)\n",
      "  adding: test_predictions/test_image_2_flash2_18_png.rf.4a3b8afe0cb430dc3aa0de25aedca8e7.jpg (deflated 40%)\n",
      "  adding: test_predictions/test_image_7_cut2_13_png.rf.f42995a226dd05307742f952d4547cbb.jpg (deflated 41%)\n",
      "  adding: test_predictions/test_image_3_flash2_11_png.rf.7c2a5f23237db59113bcf540aac6ba98.jpg (deflated 37%)\n",
      "  adding: test_predictions/test_image_6_cut2_12_png.rf.02e143627310b545a5360bb84b3919ab.jpg (deflated 40%)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_904052de-a277-45a2-aba6-fc8d58945d48\", \"test_predictions.zip\", 95598)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install pycocotools\n",
    "!pip install pycocotools\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import Compose, ToTensor, RandomHorizontalFlip, RandomRotation, ColorJitter\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Set seed\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Collate function\n",
    "def collate_fn(batch):\n",
    "    images, targets = zip(*batch)\n",
    "    # Ensure targets are lists of dictionaries\n",
    "    targets = [t if isinstance(t, list) else [t] for t in targets]\n",
    "    # Convert COCO format to Faster R-CNN format\n",
    "    formatted_targets = []\n",
    "    for t in targets:\n",
    "        formatted_t = {}\n",
    "        for ann in t:  # Process each annotation (should be one per image)\n",
    "            formatted_t['boxes'] = torch.tensor([[ann['bbox'][0], ann['bbox'][1],\n",
    "                                                 ann['bbox'][0] + ann['bbox'][2],\n",
    "                                                 ann['bbox'][1] + ann['bbox'][3]]],\n",
    "                                                dtype=torch.float32)\n",
    "            formatted_t['labels'] = torch.tensor([ann['category_id']], dtype=torch.int64)\n",
    "            formatted_t['image_id'] = torch.tensor([ann['image_id']], dtype=torch.int64)\n",
    "        formatted_targets.append(formatted_t)\n",
    "    return images, formatted_targets\n",
    "\n",
    "# Paths (update these)\n",
    "images_root = '/content/drive/MyDrive/Dataset/train'  # E.g., '/content/drive/MyDrive/images/'\n",
    "coco_ann_file = '/content/drive/MyDrive/Dataset/train/_annotations.coco.json'  # E.g., '/content/drive/MyDrive/annotations.json'\n",
    "\n",
    "# Verify dataset\n",
    "if not os.path.exists(coco_ann_file) or not os.path.exists(images_root):\n",
    "    raise FileNotFoundError(\"Check paths: images_root or coco_ann_file not found\")\n",
    "image_files = os.listdir(images_root)\n",
    "if len(image_files) != 95:\n",
    "    print(f\"Warning: Found {len(image_files)} images, expected 95\")\n",
    "coco = COCO(coco_ann_file)\n",
    "json_files = set(coco.imgs[i]['file_name'] for i in coco.imgs)\n",
    "extracted_files = set(os.listdir(images_root))\n",
    "missing = json_files - extracted_files\n",
    "if missing:\n",
    "    print(f\"Missing images: {missing}\")\n",
    "else:\n",
    "    print(\"All images found\")\n",
    "\n",
    "# Debug dataset\n",
    "full_dataset = CocoDetection(root=images_root, annFile=coco_ann_file, transform=ToTensor())\n",
    "print(\"Debugging dataset:\")\n",
    "for i, (img, target) in enumerate(full_dataset):\n",
    "    print(f\"Sample {i}: Target = {target}\")\n",
    "    if i == 2:\n",
    "        break\n",
    "\n",
    "# Balanced split\n",
    "def balanced_split(dataset, train_size, test_size):\n",
    "    cut_indices = [i for i, (_, target) in enumerate(dataset) if target[0]['category_id'] == 1]\n",
    "    flash_indices = [i for i, (_, target) in enumerate(dataset) if target[0]['category_id'] == 2]\n",
    "    if len(cut_indices) < 5 or len(flash_indices) < 5:\n",
    "        raise ValueError(\"Not enough images for balanced test split\")\n",
    "    random.shuffle(cut_indices)\n",
    "    random.shuffle(flash_indices)\n",
    "    test_indices = cut_indices[:5] + flash_indices[:5]\n",
    "    train_indices = list(set(range(len(dataset))) - set(test_indices))\n",
    "    return random_split(dataset, [len(train_indices), len(test_indices)], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Transforms\n",
    "train_transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip(0.5),\n",
    "    RandomRotation(10),\n",
    "    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
    "])\n",
    "test_transform = ToTensor()\n",
    "\n",
    "# Load dataset\n",
    "full_dataset = CocoDetection(root=images_root, annFile=coco_ann_file, transform=test_transform)\n",
    "train_dataset, test_dataset = balanced_split(full_dataset, 85, 10)\n",
    "train_dataset.dataset.transform = train_transform\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=3)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Training\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += losses.item()\n",
    "    scheduler.step()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'defect_detection_model.pth')\n",
    "print(\"Model saved to 'defect_detection_model.pth'\")\n",
    "\n",
    "# Inference and visualization\n",
    "model.eval()\n",
    "class_names = ['background', 'Cut', 'Flash']\n",
    "os.makedirs('test_predictions', exist_ok=True)\n",
    "\n",
    "coco_gt = COCO(coco_ann_file)\n",
    "coco_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (images, targets) in enumerate(test_loader):\n",
    "        images = [img.to(device) for img in images]\n",
    "        preds = model(images)\n",
    "\n",
    "        img = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "        if img.max() <= 1.0:\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(img)\n",
    "\n",
    "        img_id = targets[0]['image_id'].item()\n",
    "        file_name = test_dataset.dataset.coco.imgs[img_id]['file_name']\n",
    "        print(f\"\\nTest Image {idx+1} (File: {file_name}):\")\n",
    "        gt_box = [targets[0]['boxes'][0][0], targets[0]['boxes'][0][1],\n",
    "                  targets[0]['boxes'][0][2] - targets[0]['boxes'][0][0],\n",
    "                  targets[0]['boxes'][0][3] - targets[0]['boxes'][0][1]]  # Convert to [x, y, w, h]\n",
    "        print(f\"Ground Truth: {class_names[targets[0]['labels'][0]]}, Box: {gt_box}\")\n",
    "\n",
    "        for pred in preds:\n",
    "            boxes = pred['boxes'].cpu().numpy()\n",
    "            labels = pred['labels'].cpu().numpy()\n",
    "            scores = pred['scores'].cpu().numpy()\n",
    "\n",
    "            for box, label, score in zip(boxes, labels, scores):\n",
    "                if score > 0.5:\n",
    "                    print(f\"  - Predicted: Class: {class_names[label]}, Score: {score:.2f}, Box: {box}\")\n",
    "                    rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=2, edgecolor='r', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.text(box[0], box[1], f\"{class_names[label]} {score:.2f}\", bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "            for box, label, score in zip(boxes, labels, scores):\n",
    "                if score > 0.5:\n",
    "                    coco_results.append({\n",
    "                        \"image_id\": img_id,\n",
    "                        \"category_id\": label,\n",
    "                        \"bbox\": [float(box[0]), float(box[1]), float(box[2]-box[0]), float(box[3]-box[1])],\n",
    "                        \"score\": float(score)\n",
    "                    })\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f'test_predictions/test_image_{idx+1}_{file_name}')\n",
    "        plt.close()\n",
    "        print(f\"Visualization saved to 'test_predictions/test_image_{idx+1}_{file_name}'\")\n",
    "\n",
    "# Compute mAP\n",
    "if coco_results:\n",
    "    coco_dt = coco_gt.loadRes(coco_results)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "    coco_eval.params.iouThrs = np.array([0.5])\n",
    "    coco_eval.params.imgIds = [test_dataset.dataset.coco.imgs[i]['id'] for i in test_dataset.indices]\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    print(f\"Test mAP@0.5: {coco_eval.stats[0]:.4f}\")\n",
    "else:\n",
    "    print(\"No predictions above threshold for mAP calculation.\")\n",
    "\n",
    "# Download outputs\n",
    "from google.colab import files\n",
    "files.download('defect_detection_model.pth')\n",
    "!zip -r test_predictions.zip test_predictions/\n",
    "files.download('test_predictions.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1755705842634,
     "user": {
      "displayName": "Krishnan R",
      "userId": "09129740586849182851"
     },
     "user_tz": -330
    },
    "id": "P0KnOMclOQFM",
    "outputId": "b8a81467-2247-4ea5-fa8f-c653bae11f27"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_ec59eedf-9ba3-40b3-bb79-a7e62d71d53f\", \"defect_detection_model.pth\", 165752788)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: test_predictions/ (stored 0%)\n",
      "updating: test_predictions/test_image_8_flash2_5_png.rf.710edfcdbdd2d6d6ea9bdc3cf3e05553.jpg (deflated 40%)\n",
      "updating: test_predictions/test_image_1_cut1_3_png.rf.303085f18402fedbe55629905e37cdc4.jpg (deflated 40%)\n",
      "updating: test_predictions/test_image_5_flash1_8_png.rf.1492fa6599ce249487594a6b2e7207d1.jpg (deflated 39%)\n",
      "updating: test_predictions/test_image_9_flash1_1_png.rf.023a77ad22904bdb26d59a117891fe0a.jpg (deflated 40%)\n",
      "updating: test_predictions/test_image_4_cut1_6_png.rf.6ffd8dd7bdc901e69026880b32ad1446.jpg (deflated 42%)\n",
      "updating: test_predictions/test_image_10_flash1_11_png.rf.dc5b26f964ae8cd1170b20d2b212cde5.jpg (deflated 37%)\n",
      "updating: test_predictions/test_image_2_flash2_18_png.rf.4a3b8afe0cb430dc3aa0de25aedca8e7.jpg (deflated 40%)\n",
      "updating: test_predictions/test_image_7_cut2_13_png.rf.f42995a226dd05307742f952d4547cbb.jpg (deflated 41%)\n",
      "updating: test_predictions/test_image_3_flash2_11_png.rf.7c2a5f23237db59113bcf540aac6ba98.jpg (deflated 37%)\n",
      "updating: test_predictions/test_image_6_cut2_12_png.rf.02e143627310b545a5360bb84b3919ab.jpg (deflated 40%)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_a0d4bff9-3a9f-4eed-873b-e014b7134e9a\", \"test_predictions.zip\", 95598)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('defect_detection_model.pth')\n",
    "!zip -r test_predictions.zip test_predictions/\n",
    "files.download('test_predictions.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNLNb7O51UR4qFyhkRomUeF",
   "gpuType": "T4",
   "mount_file_id": "1Mm6puN9AY4x5DBoabdGHLYofrEBvA4bz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
